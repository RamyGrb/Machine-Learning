{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PowerCo business & data science case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HEC - BCG Gamma Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# coding: utf-8\n",
    "\n",
    "\"\"\"\n",
    " BCG Gamma PowerCo usecase\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "__version__    = \"0.1\"\n",
    "__author__     = \"Martin Pocquet\"\n",
    "__maintainer__ = \"Martin Pocquet\"\n",
    "__email__      = \"pocquet.martin@bcg.com\"\n",
    "__date__       = \"May 15st, 2019\"\n",
    "__status__     = \"Prototype\"  # Development, Production\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your local machine\n",
    "\n",
    "wdir = 'C:\\\\Users\\\\Pocquet Martin\\\\Desktop\\\\Atelier HEC\\\\demo\\\\Compass'\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir(wdir)\n",
    "print(\"Working directory \" + wdir + \".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the different files\n",
    "\n",
    "pricing_df = pd.read_csv('pycharm/data/powerco/1. Original data/A. Pricing data.csv')\n",
    "print('Pricing data shape:', pricing_df.shape)\n",
    "\n",
    "energy_df = \n",
    "print('Energy data shape:', energy_df.shape)\n",
    "\n",
    "finance_df = \n",
    "print('Finance data shape:', finance_df.shape)\n",
    "\n",
    "crm_df = \n",
    "print('CRM data shape:', crm_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the different datasets together\n",
    "\n",
    "merged_df = \n",
    "print('Merged data shape:', merged_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset can now be loaded from the given database\n",
    "\n",
    "merged_df = pd.read_csv('pycharm/data/powerco/2. Combined data/0. powerco_original_data.csv')\n",
    "print('Merged data shape:', merged_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What filters can we apply ?\n",
    "# Create a cleaned dataset\n",
    "\n",
    "cleaned_df = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset can now be loaded from the given database\n",
    "\n",
    "cleaned_df = pd.read_csv('pycharm/data/powerco/2. Combined data/I. powerco_cleaned_data.csv')\n",
    "print('Cleaned data shape:', cleaned_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra rows from another customer base has been found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset can now be loaded from the given database\n",
    "\n",
    "extra_rows_df = pd.read_csv('pycharm/data/powerco/2. Combined data/II. powerco_extra_rows.csv')\n",
    "print('Extra rows data shape:', extra_rows_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional features can be added (e.g Sales channel data)\n",
    "# Create the final dataset\n",
    "\n",
    "extra_var_df = \n",
    "print('Extra var data shape:', extra_var_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset can now be loaded from the given database\n",
    "\n",
    "extra_var_df = pd.read_csv('pycharm/data/powerco/2. Combined data/III. powerco_extra_columns.csv')\n",
    "extra_var_df.drop('Unnamed: 0', 1, inplace=True)\n",
    "print('Extra var data shape:', extra_var_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there several features you want to discard for the training?\n",
    "# GDPR, business rules, ...\n",
    "\n",
    "extra_var_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to numerical data (if needed)\n",
    "extra_var_df['also_gas_client'] = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the column \"target_churned\" as the variable to predict\n",
    "# Design a ML model\n",
    "# Apply on 30% of the data for testing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = (extra_var_df.drop(['target_churned', 'id'], 1))\n",
    "y = (extra_var_df['target_churned'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on X_test\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "preds = clf.predict_proba(X_test)[:,1]\n",
    "print('ROC AUC score: ', roc_auc_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact on margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the impact on margin\n",
    "# in function of the probability threshold used to predict churners\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
